// ============================================================================
// KORE Parser v2 - Robust Implementation with Error Recovery
// ============================================================================
// Key improvements over v1:
// - Error recovery instead of panic() - accumulates errors and continues
// - Recursion depth limit - prevents stack overflow
// - Cleaner whitespace handling - single context-aware function
// - Proper Type AST nodes - not just strings
// - Extended pattern matching support
// - Sync point recovery for resilience
// ============================================================================

use ast
use span
use diagnostic

// =============================================================================
// Parse Error & Result Types
// =============================================================================

struct ParseError:
    message: String
    span: Span
    severity: String  // "error", "warning", "hint"

impl ParseError:
    pub fn new(message: String, span: Span) -> ParseError:
        return ParseError { message: message, span: span, severity: "error" }
    
    pub fn warning(message: String, span: Span) -> ParseError:
        return ParseError { message: message, span: span, severity: "warning" }

// =============================================================================
// Type AST - Proper structured types instead of strings
// =============================================================================

enum TypeExpr:
    Named(String)                              // Int, String, MyType
    Generic(String, Array)                     // Array<Int>, Option<T>
    Tuple(Array)                               // (Int, String)
    Function(Array, TypeExpr)                  // fn(Int, Int) -> Bool
    Optional(TypeExpr)                         // ?Int (sugar for Option<Int>)
    Reference(TypeExpr)                        // &T
    MutReference(TypeExpr)                     // &mut T
    Unit                                       // ()

impl TypeExpr:
    pub fn to_string(self) -> String:
        match self:
            Named(name) => return name
            Generic(name, args) =>
                let arg_strs = []
                for arg in args:
                    push(arg_strs, arg.to_string())
                return name + "<" + join(arg_strs, ", ") + ">"
            Tuple(types) =>
                let type_strs = []
                for t in types:
                    push(type_strs, t.to_string())
                return "(" + join(type_strs, ", ") + ")"
            Function(params, ret) =>
                let param_strs = []
                for p in params:
                    push(param_strs, p.to_string())
                return "fn(" + join(param_strs, ", ") + ") -> " + ret.to_string()
            Optional(inner) =>
                return "?" + inner.to_string()
            Reference(inner) =>
                return "&" + inner.to_string()
            MutReference(inner) =>
                return "&mut " + inner.to_string()
            Unit =>
                return "()"
        return "Unknown"

// =============================================================================
// Extended Pattern Matching
// =============================================================================

enum PatternV2:
    Wildcard                                           // _
    Ident(String)                                      // x
    Literal(Expr)                                      // 42, "hello"
    Variant(String, String, Array)                     // Enum::Variant(x, y)
    Tuple(Array)                                       // (a, b, c)
    Struct(String, Array)                              // Point { x: a, y: b }
    Or(Array)                                          // a | b | c
    As(PatternV2, String)                              // pattern as name
    Rest                                               // ..

struct PatternFieldV2:
    name: String
    pattern: PatternV2

// =============================================================================
// Parser State
// =============================================================================

// const MAX_NEST_LEV: Int = 10000
// const MAX_ERRORS: Int = 100

struct ParserV2:
    tokens: Array // <Token>
    pos: Int
    errors: Array // <ParseError>
    nest_lev: Int
    sync_pos: Int      // Last sync position for error recovery
    sync_cnt: Int      // Number of advance calls without progress
    source: String     // Source content for location lookups
    file: String       // File path for error messages

// impl ParserV2:
pub fn parser_new(tokens: Array, source: String, file: String) -> ParserV2:
    return ParserV2 {
        tokens: tokens,
        pos: 0,
        errors: [],
        nest_lev: 0,
        sync_pos: 0,
        sync_cnt: 0,
        source: source,
        file: file
    }

pub fn parser_has_errors(p: ParserV2) -> Bool:
    return array_len(p.errors) != 0

// =============================================================================
// Core Token Access
// =============================================================================

fn parser_is_eof(p: ParserV2) -> Bool:
    if p.pos >= array_len(p.tokens):
        return true
    let tok = p.tokens[p.pos]
    return tok.is_eof()

fn parser_peek(p: ParserV2) -> Token:
    if parser_is_eof(p):
        return Token::new(TokenType::Eof, Span::empty(), "")
    return p.tokens[p.pos]

fn parser_peek_n(p: ParserV2, n: Int) -> Token:
    let idx = p.pos + n
    if idx < 0 || idx >= array_len(p.tokens):
        return Token::new(TokenType::Eof, Span::empty(), "")
    return p.tokens[idx]

fn parser_advance(p: ParserV2) -> Token:
    let tok = parser_peek(p)
    if !parser_is_eof(p):
        p.pos = p.pos + 1
    return tok

fn parser_check(p: ParserV2, variant: String) -> Bool:
    if parser_is_eof(p):
        return false
    let tok = parser_peek(p)
    if str_eq(variant, "Ident"): return tok.is_ident()
    if str_eq(variant, "Eof"): return tok.is_eof()
    if str_eq(variant, "Newline"): return tok.is_newline()
    if str_eq(variant, "Indent"): return tok.is_indent()
    if str_eq(variant, "Dedent"): return tok.is_dedent()
    if str_eq(variant, "Error"): return tok.is_error()
    return str_eq(variant_of(tok.type), variant)

fn parser_check_lexeme(p: ParserV2, lex: String) -> Bool:
    if parser_is_eof(p):
        return false
    return str_eq(parser_peek(p).lexeme, lex)

fn parser_match(p: ParserV2, variant: String) -> Bool:
    if parser_check(p, variant):
        let _ = parser_advance(p)
        return true
    return false

fn parser_match_lexeme(p: ParserV2, lex: String) -> Bool:
    if parser_check_lexeme(p, lex):
        let _ = parser_advance(p)
        return true
    return false

fn parser_match_keyword(p: ParserV2, kw: String) -> Bool:
    let tok = parser_peek(p)
    if tok.is_keyword(kw):
        let _ = parser_advance(p)
        return true
    return false

// =============================================================================
// Error Handling & Recovery
// =============================================================================

fn parser_error(p: ParserV2, msg: String) -> Unit:
    let tok = parser_peek(p)
    let err = ParseError::new(msg, tok.span)
    println("[PARSER ERROR] " + msg)
    push(p.errors, err)
    
    // Limit errors to prevent infinite error accumulation
    if array_len(p.errors) >= 100: // MAX_ERRORS
        println("FATAL: Too many parse errors, stopping")
        parser_report_and_panic(p, "Too many errors")

fn parser_error_expected(p: ParserV2, expected: String) -> Unit:
    let tok = parser_peek(p)
    let msg = "Expected " + expected + ", found '" + tok.lexeme + "'"
    parser_error(p, msg)

// NEW: Pretty error reporting with diagnostic rendering
fn parser_report_and_panic(p: ParserV2, msg: String) -> Unit:
    let tok = parser_peek(p)
    
    // Create diagnostic bundle
    let bundle = DiagnosticBundle::new()
    bundle.add_source(p.file, p.source)
    
    // Add the fatal error
    bundle.error(msg, tok.span, p.file)
    
    // Add any accumulated parse errors as notes
    for err in p.errors:
        let note = Diagnostic::note(err.message, err.span, p.file)
        bundle.add(note)
    
    // Render all errors
    bundle.render()
    
    // Exit
    panic("Parser failed - see errors above")

fn parser_expect(p: ParserV2, lex: String) -> Token:
    let tok = parser_peek(p)
    if str_eq(tok.lexeme, lex):
        return parser_advance(p)
    
    // Report with nice diagnostic then panic
    let msg = "Expected '" + lex + "' but found '" + tok.lexeme + "'"
    parser_report_and_panic(p, msg)
    return tok  // Unreachable but needed for type checker

fn parser_expect_keyword(p: ParserV2, kw: String) -> Token:
    let tok = parser_peek(p)
    if tok.is_keyword(kw):
        return parser_advance(p)
    
    // Report with nice diagnostic then panic
    let msg = "Expected keyword '" + kw + "' but found '" + tok.lexeme + "'"
    parser_report_and_panic(p, msg)
    return tok  // Unreachable but needed for type checker

// Sync point tokens - used for error recovery
fn is_sync_point(tok: Token) -> Bool:
    let lex = tok.lexeme
    if str_eq(lex, "fn"): return true
    if str_eq(lex, "pub"): return true
    if str_eq(lex, "struct"): return true
    if str_eq(lex, "enum"): return true
    if str_eq(lex, "impl"): return true
    if str_eq(lex, "use"): return true
    if str_eq(lex, "let"): return true
    if str_eq(lex, "var"): return true
    if str_eq(lex, "return"): return true
    if str_eq(lex, "if"): return true
    if str_eq(lex, "while"): return true
    if str_eq(lex, "for"): return true
    if str_eq(lex, "match"): return true
    if str_eq(lex, "loop"): return true
    if str_eq(variant_of(tok.type), "Dedent"): return true
    if str_eq(variant_of(tok.type), "Eof"): return true
    return false

fn parser_advance_to_sync(p: ParserV2) -> Unit:
    // Skip tokens until we reach a sync point
    while !parser_is_eof(p):
        let tok = parser_peek(p)
        
        // Check for progress to prevent infinite loops
        if p.pos == p.sync_pos:
            p.sync_cnt = p.sync_cnt + 1
            if 10 < p.sync_cnt:
                // Force progress
                let _ = parser_advance(p)
                p.sync_cnt = 0
                return
        else:
            p.sync_pos = p.pos
            p.sync_cnt = 0
        
        if is_sync_point(tok):
            return
        
        let _ = parser_advance(p)

// =============================================================================
// Recursion Depth Tracking
// =============================================================================

fn parser_inc_nest(p: ParserV2) -> Bool:
    p.nest_lev = p.nest_lev + 1
    if 10000 < p.nest_lev: // Use < to avoid potential Gt issues
        parser_error(p, "Exceeded maximum nesting depth")
        return false
    return true

fn parser_dec_nest(p: ParserV2) -> Unit:
    p.nest_lev = p.nest_lev - 1

// =============================================================================
// Whitespace Handling - Unified approach
// =============================================================================

enum ParseContext:
    TopLevel    // At top level of file
    Block       // Inside a block (indented)
    Parens      // Inside parentheses/brackets/braces

fn parser_skip_ws(p: ParserV2, ctx: ParseContext) -> Unit:
    loop:
        if parser_is_eof(p):
            break
        
        let tok = parser_peek(p)
        let v = variant_of(tok.type)
        
        match ctx:
            TopLevel =>
                // Only skip newlines at top level
                if str_eq(v, "Newline"):
                    let _ = parser_advance(p)
                else:
                    break
            Block =>
                // Skip newlines in blocks
                if str_eq(v, "Newline"):
                    let _ = parser_advance(p)
                else:
                    break
            Parens =>
                // Skip newlines, indents, dedents inside parens
                // (lexer v2 handles this with paren_depth, but be robust)
                if str_eq(v, "Newline") || str_eq(v, "Indent") || str_eq(v, "Dedent"):
                    let _ = parser_advance(p)
                else:
                    break

fn parser_skip_newlines(p: ParserV2) -> Unit:
    parser_skip_ws(p, ParseContext::Block)

// =============================================================================
// Type Parsing - Returns TypeExpr instead of String
// =============================================================================

fn parse_type_expr(p: ParserV2) -> TypeExpr:
    // Handle tuple types (A, B)
    if parser_check_lexeme(p, "("):
        let _ = parser_advance(p)
        
        // Empty tuple ()
        if parser_check_lexeme(p, ")"):
            let _ = parser_advance(p)
            return TypeExpr::Unit
        
        let first = parse_type_expr(p)
        
        // Check for tuple
        if parser_check_lexeme(p, ","):
            let types = [first]
            while parser_match_lexeme(p, ","):
                parser_skip_ws(p, ParseContext::Parens)
                push(types, parse_type_expr(p))
            let _ = parser_expect(p, ")")
            return TypeExpr::Tuple(types)
        
        let _ = parser_expect(p, ")")
        return first
    
    // Handle reference types &T, &mut T
    if parser_check_lexeme(p, "&"):
        let _ = parser_advance(p)
        if parser_match_keyword(p, "mut"):
            return TypeExpr::MutReference(parse_type_expr(p))
        return TypeExpr::Reference(parse_type_expr(p))
    
    // Handle optional ?T
    if parser_check_lexeme(p, "?"):
        let _ = parser_advance(p)
        return TypeExpr::Optional(parse_type_expr(p))
    
    // Handle function types fn(A, B) -> C
    if parser_match_keyword(p, "fn"):
        let _ = parser_expect(p, "(")
        let params = []
        if !parser_check_lexeme(p, ")"):
            push(params, parse_type_expr(p))
            while parser_match_lexeme(p, ","):
                parser_skip_ws(p, ParseContext::Parens)
                push(params, parse_type_expr(p))
        let _ = parser_expect(p, ")")
        
        let ret = TypeExpr::Unit
        if parser_match_lexeme(p, "->"):
            ret = parse_type_expr(p)
        
        return TypeExpr::Function(params, ret)
    
    // Named type with optional generic args
    let name_tok = parser_advance(p)
    let name = name_tok.lexeme
    
    // Check for generic parameters
    if parser_check_lexeme(p, "<"):
        let _ = parser_advance(p)
        let args = []
        if !parser_check_lexeme(p, ">"):
            push(args, parse_type_expr(p))
            while parser_match_lexeme(p, ","):
                parser_skip_ws(p, ParseContext::Parens)
                push(args, parse_type_expr(p))
        let _ = parser_expect(p, ">")
        return TypeExpr::Generic(name, args)
    
    return TypeExpr::Named(name)

// Helper to convert TypeExpr to string for legacy compatibility
fn type_expr_to_string(te: TypeExpr) -> String:
    return te.to_string()

// =============================================================================
// Pattern Parsing - Extended patterns
// =============================================================================

fn parse_pattern_v2(p: ParserV2) -> PatternV2:
    if !parser_inc_nest(p):
        return PatternV2::Wildcard
    
    let result = parse_pattern_or(p)
    
    // Check for 'as' binding
    if parser_match_keyword(p, "as"):
        let name = parser_advance(p).lexeme
        result = PatternV2::As(result, name)
    
    parser_dec_nest(p)
    return result

fn parse_pattern_or(p: ParserV2) -> PatternV2:
    let first = parse_pattern_primary(p)
    
    // Check for | alternation
    if parser_check_lexeme(p, "|"):
        let patterns = [first]
        while parser_match_lexeme(p, "|"):
            parser_skip_ws(p, ParseContext::Parens)
            push(patterns, parse_pattern_primary(p))
        return PatternV2::Or(patterns)
    
    return first

fn parse_pattern_primary(p: ParserV2) -> PatternV2:
    let tok = parser_peek(p)
    
    // Wildcard
    if str_eq(tok.lexeme, "_"):
        let _ = parser_advance(p)
        return PatternV2::Wildcard
    
    // Rest pattern ..
    if str_eq(tok.lexeme, ".."):
        let _ = parser_advance(p)
        return PatternV2::Rest
    
    // Tuple pattern (a, b, c)
    if str_eq(tok.lexeme, "("):
        let _ = parser_advance(p)
        let patterns = []
        if !parser_check_lexeme(p, ")"):
            push(patterns, parse_pattern_v2(p))
            while parser_match_lexeme(p, ","):
                parser_skip_ws(p, ParseContext::Parens)
                if !parser_check_lexeme(p, ")"):
                    push(patterns, parse_pattern_v2(p))
        let _ = parser_expect(p, ")")
        return PatternV2::Tuple(patterns)
    
    // Identifier or variant pattern
    if tok.is_ident():
        let _ = parser_advance(p)
        let name = tok.lexeme
        
        // Check for namespaced variant: Enum::Variant
        if parser_check_lexeme(p, "::"):
            let _ = parser_advance(p)
            let variant = parser_advance(p).lexeme
            
            // Check for bindings
            if parser_check_lexeme(p, "("):
                let _ = parser_advance(p)
                let bindings = []
                if !parser_check_lexeme(p, ")"):
                    push(bindings, parse_pattern_v2(p))
                    while parser_match_lexeme(p, ","):
                        parser_skip_ws(p, ParseContext::Parens)
                        push(bindings, parse_pattern_v2(p))
                let _ = parser_expect(p, ")")
                return PatternV2::Variant(name, variant, bindings)
            
            return PatternV2::Variant(name, variant, [])
        
        // Check for struct pattern: Name { field: pat }
        if parser_check_lexeme(p, "{"):
            let _ = parser_advance(p)
            let fields = []
            if !parser_check_lexeme(p, "}"):
                let field_name = parser_advance(p).lexeme
                let _ = parser_expect(p, ":")
                let field_pat = parse_pattern_v2(p)
                push(fields, PatternFieldV2 { name: field_name, pattern: field_pat })
                
                while parser_match_lexeme(p, ","):
                    parser_skip_ws(p, ParseContext::Parens)
                    if parser_check_lexeme(p, "}"):
                        break
                    let fn2 = parser_advance(p).lexeme
                    let _ = parser_expect(p, ":")
                    let fp2 = parse_pattern_v2(p)
                    push(fields, PatternFieldV2 { name: fn2, pattern: fp2 })
            let _ = parser_expect(p, "}")
            return PatternV2::Struct(name, fields)
        
        // Check for variant with bindings (no namespace): Variant(x, y)
        if parser_check_lexeme(p, "("):
            let _ = parser_advance(p)
            let bindings = []
            if !parser_check_lexeme(p, ")"):
                push(bindings, parse_pattern_v2(p))
                while parser_match_lexeme(p, ","):
                    parser_skip_ws(p, ParseContext::Parens)
                    push(bindings, parse_pattern_v2(p))
            let _ = parser_expect(p, ")")
            return PatternV2::Variant("", name, bindings)
        
        return PatternV2::Ident(name)
    
    // Literal pattern (numbers, strings, bools)
    let expr = parse_primary_expr(p)
    return PatternV2::Literal(expr)

// =============================================================================
// Expression Parsing with Precedence
// =============================================================================

fn parse_expr_v2(p: ParserV2) -> Expr:
    if !parser_inc_nest(p):
        return Expr::None
    
    let result = parse_or_expr(p)
    parser_dec_nest(p)
    return result

fn parse_or_expr(p: ParserV2) -> Expr:
    let left = parse_and_expr(p)
    while parser_match_lexeme(p, "||"):
        let right = parse_and_expr(p)
        left = Expr::Binary(left, "||", right)
    return left

fn parse_and_expr(p: ParserV2) -> Expr:
    let left = parse_equality_expr(p)
    while parser_match_lexeme(p, "&&"):
        let right = parse_equality_expr(p)
        left = Expr::Binary(left, "&&", right)
    return left

fn parse_equality_expr(p: ParserV2) -> Expr:
    let left = parse_comparison_expr(p)
    loop:
        let tok = parser_peek(p)
        if str_eq(tok.lexeme, "==") || str_eq(tok.lexeme, "!="):
            let op = parser_advance(p).lexeme
            let right = parse_comparison_expr(p)
            left = Expr::Binary(left, op, right)
        else:
            break
    return left

fn parse_comparison_expr(p: ParserV2) -> Expr:
    let left = parse_bitwise_or(p)
    loop:
        let tok = parser_peek(p)
        if str_eq(tok.lexeme, "<") || str_eq(tok.lexeme, ">") || str_eq(tok.lexeme, "<=") || str_eq(tok.lexeme, ">="):
            let op = parser_advance(p).lexeme
            let right = parse_bitwise_or(p)
            left = Expr::Binary(left, op, right)
        else:
            break
    return left

fn parse_bitwise_or(p: ParserV2) -> Expr:
    let left = parse_bitwise_xor(p)
    while parser_match_lexeme(p, "|"):
        let right = parse_bitwise_xor(p)
        left = Expr::Binary(left, "|", right)
    return left

fn parse_bitwise_xor(p: ParserV2) -> Expr:
    let left = parse_bitwise_and(p)
    while parser_match_lexeme(p, "^"):
        let right = parse_bitwise_and(p)
        left = Expr::Binary(left, "^", right)
    return left

fn parse_bitwise_and(p: ParserV2) -> Expr:
    let left = parse_shift(p)
    while parser_match_lexeme(p, "&"):
        let right = parse_shift(p)
        left = Expr::Binary(left, "&", right)
    return left

fn parse_shift(p: ParserV2) -> Expr:
    let left = parse_term_expr(p)
    loop:
        let tok = parser_peek(p)
        if str_eq(tok.lexeme, "<<") || str_eq(tok.lexeme, ">>"):
            let op = parser_advance(p).lexeme
            let right = parse_term_expr(p)
            left = Expr::Binary(left, op, right)
        else:
            break
    return left

fn parse_term_expr(p: ParserV2) -> Expr:
    let left = parse_factor_expr(p)
    loop:
        let tok = parser_peek(p)
        // Skip if it's a string literal containing + or -
        if str_eq(variant_of(tok.type), "String"):
            break
        if str_eq(tok.lexeme, "+") || str_eq(tok.lexeme, "-"):
            let op = parser_advance(p).lexeme
            let right = parse_factor_expr(p)
            left = Expr::Binary(left, op, right)
        else:
            break
    return left

fn parse_factor_expr(p: ParserV2) -> Expr:
    let left = parse_unary_expr(p)
    loop:
        let tok = parser_peek(p)
        if str_eq(variant_of(tok.type), "String"):
            break
        if str_eq(tok.lexeme, "*") || str_eq(tok.lexeme, "/") || str_eq(tok.lexeme, "%"):
            let op = parser_advance(p).lexeme
            let right = parse_unary_expr(p)
            left = Expr::Binary(left, op, right)
        else:
            break
    return left

fn parse_unary_expr(p: ParserV2) -> Expr:
    let tok = parser_peek(p)
    if str_eq(variant_of(tok.type), "String"):
        return parse_postfix_expr(p)
    if str_eq(tok.lexeme, "!") || str_eq(tok.lexeme, "-") || str_eq(tok.lexeme, "&") || str_eq(tok.lexeme, "*"):
        let op = parser_advance(p).lexeme
        let operand = parse_unary_expr(p)
        return Expr::Unary(op, operand)
    return parse_postfix_expr(p)

fn parse_type_args_v2(p: ParserV2) -> Array<String>:
    if !parser_check_lexeme(p, "<"):
        return []

    // Heuristic: Check for whitespace between previous token and '<'
    // to distinguish generic arguments from a less-than comparison.
    let prev_pos = p.pos - 1
    if prev_pos >= 0 && p.pos < array_len(p.tokens):
        let prev_tok = p.tokens[prev_pos]
        let current_tok = p.tokens[p.pos]
        if prev_tok.span.end != current_tok.span.start:
             return [] // Found whitespace, assume comparison op

    let _ = parser_advance(p) // Consume '<'
    let args = []
    parser_skip_ws(p, ParseContext::Parens)
    
    if !parser_check_lexeme(p, ">"):
        push(args, type_expr_to_string(parse_type_expr(p)))
        while parser_match_lexeme(p, ","):
            parser_skip_ws(p, ParseContext::Parens)
            if parser_check_lexeme(p, ">"):
                break
            push(args, type_expr_to_string(parse_type_expr(p)))
    
    parser_skip_ws(p, ParseContext::Parens)
    let _ = parser_expect(p, ">")
    return args

fn parse_postfix_expr(p: ParserV2) -> Expr:
    let expr = parse_primary_expr(p)
    
    loop:
        let tok = parser_peek(p)
        let lex = tok.lexeme
        let tk = variant_of(tok.type)
        
        // Skip string literals as operators
        if str_eq(tk, "String"):
            break
        
        // Field access or method call
        if str_eq(lex, "."):
            let _ = parser_advance(p)
            let field = parser_advance(p).lexeme
            
            let type_args = parse_type_args_v2(p)
            
            if parser_check_lexeme(p, "("):
                let _ = parser_advance(p)
                let args = parse_args_v2(p)
                expr = Expr::MethodCall(expr, field, type_args, args)
            else:
                if array_len(type_args) > 0:
                    parser_error(p, "Unexpected generic arguments on field access")
                expr = Expr::Field(expr, field)
            continue
        
        // Index access
        if str_eq(lex, "["):
            let _ = parser_advance(p)
            parser_skip_ws(p, ParseContext::Parens)
            let index = parse_expr_v2(p)
            parser_skip_ws(p, ParseContext::Parens)
            let _ = parser_expect(p, "]")
            expr = Expr::Index(expr, index)
            continue
        
        // Function call
        let type_args = parse_type_args_v2(p)
        if str_eq(lex, "("):
            let _ = parser_advance(p)
            let args = parse_args_v2(p)
            expr = Expr::Call(expr, type_args, args)
            continue
        else:
             if array_len(type_args) > 0:
                parser_error(p, "Unexpected generic arguments")
        
        break
    
    return expr

fn parse_args_v2(p: ParserV2) -> Array<Expr>:
    let args = []
    parser_skip_ws(p, ParseContext::Parens)
    
    if !parser_check_lexeme(p, ")"):
        push(args, parse_expr_v2(p))
        
        while parser_match_lexeme(p, ","):
            parser_skip_ws(p, ParseContext::Parens)
            if parser_check_lexeme(p, ")"):
                break
            push(args, parse_expr_v2(p))
    
    parser_skip_ws(p, ParseContext::Parens)
    let _ = parser_expect(p, ")")
    return args

fn parse_primary_expr(p: ParserV2) -> Expr:
    let tok = parser_peek(p)
    let lex = tok.lexeme
    let tk = variant_of(tok.type)
    
    if str_eq(tk, "Eof"):
        parser_error(p, "Unexpected end of file in expression")
        return Expr::None
    
    if str_eq(tk, "Dedent"):
        parser_error(p, "Unexpected dedent in expression")
        return Expr::None
    
    if str_eq(tk, "Indent"):
        parser_error(p, "Unexpected indent in expression")
        return Expr::None
    
    // Parenthesized expression or tuple
    if str_eq(lex, "("):
        let _ = parser_advance(p)
        parser_skip_ws(p, ParseContext::Parens)
        
        if parser_check_lexeme(p, ")"):
            let _ = parser_advance(p)
            return Expr::Tuple([])
        
        let first = parse_expr_v2(p)
        parser_skip_ws(p, ParseContext::Parens)
        
        // Check for tuple
        if parser_check_lexeme(p, ","):
            let elements = [first]
            while parser_match_lexeme(p, ","):
                parser_skip_ws(p, ParseContext::Parens)
                if parser_check_lexeme(p, ")"):
                    break
                push(elements, parse_expr_v2(p))
                parser_skip_ws(p, ParseContext::Parens)
            let _ = parser_expect(p, ")")
            return Expr::Tuple(elements)
        
        let _ = parser_expect(p, ")")
        return first
    
    // Array literal
    if str_eq(lex, "["):
        let _ = parser_advance(p)
        let elements = []
        parser_skip_ws(p, ParseContext::Parens)
        
        while !parser_check_lexeme(p, "]"):
            push(elements, parse_expr_v2(p))
            parser_skip_ws(p, ParseContext::Parens)
            if parser_check_lexeme(p, ","):
                let _ = parser_advance(p)
                parser_skip_ws(p, ParseContext::Parens)
        
        let _ = parser_expect(p, "]")
        return Expr::Array(elements)
    
    // Struct literal
    if str_eq(lex, "{"):
        let _ = parser_advance(p)
        let fields = []
        parser_skip_ws(p, ParseContext::Parens)
        
        while !parser_check_lexeme(p, "}"):
            let fname = parser_advance(p).lexeme
            let _ = parser_expect(p, ":")
            parser_skip_ws(p, ParseContext::Parens)
            let fval = parse_expr_v2(p)
            push(fields, FieldInit { name: fname, value: fval, span: Span::empty() })
            parser_skip_ws(p, ParseContext::Parens)
            if parser_check_lexeme(p, ","):
                let _ = parser_advance(p)
                parser_skip_ws(p, ParseContext::Parens)
        
        let _ = parser_expect(p, "}")
        
        return Expr::Struct("", fields)
    
    // Lambda: |args| body
    if str_eq(lex, "|"):
        return parse_lambda(p)
    
    // Consume the token
    let _ = parser_advance(p)
    
    // Integer literal
    if str_eq(tk, "Int"):
        return Expr::Int(variant_field(tok.type, 0))
    
    // Float literal
    if str_eq(tk, "Float"):
        return Expr::Float(variant_field(tok.type, 0))
    
    // String literal
    if str_eq(tk, "String"):
        return Expr::String(variant_field(tok.type, 0))
    
    // Bool literal
    if str_eq(tk, "Bool"):
        return Expr::Bool(variant_field(tok.type, 0))
    
    // Keywords that are expressions
    if str_eq(lex, "true"):
        return Expr::Bool(true)
    if str_eq(lex, "false"):
        return Expr::Bool(false)
    if str_eq(lex, "none"):
        return Expr::None
    if str_eq(lex, "self"):
        return Expr::Ident("self")
    
    // Try to detect integer from lexeme content
    if str_len(lex) > 0:
        let first = char_code_at(lex, 0)
        if first >= 48 && first <= 57:
            return Expr::Int(to_int(lex))
    
    // Check for enum variant: Ident::Variant
    if parser_check_lexeme(p, "::"):
        let _ = parser_advance(p)
        let variant = parser_advance(p).lexeme
        
        // Check for variant with args
        if parser_check_lexeme(p, "("):
            let _ = parser_advance(p)
            let args = parse_args_v2(p)
            return Expr::EnumVariant(lex, variant, args)
        
        return Expr::EnumVariant(lex, variant, [])
    
    // Check for struct literal: Ident { field: val }
    if parser_check_lexeme(p, "{"):
        let _ = parser_advance(p)
        let fields = []
        parser_skip_ws(p, ParseContext::Parens)
        
        while !parser_check_lexeme(p, "}"):
            let fname = parser_advance(p).lexeme
            let _ = parser_expect(p, ":")
            parser_skip_ws(p, ParseContext::Parens)
            let fval = parse_expr_v2(p)
            push(fields, FieldInit { name: fname, value: fval, span: Span::empty() })
            parser_skip_ws(p, ParseContext::Parens)
            if parser_check_lexeme(p, ","):
                let _ = parser_advance(p)
                parser_skip_ws(p, ParseContext::Parens)
        
        let _ = parser_expect(p, "}")
        return Expr::Struct(lex, fields)
    
    // Default: identifier
    if tok.is_ident():
        return Expr::Ident(lex)
    
    parser_error(p, "Unexpected token in expression: '" + lex + "'")
    return Expr::None

fn parse_lambda(p: ParserV2) -> Expr:
    let None = Option::None
    let _ = parser_expect(p, "|")
    let params = []
    
    if !parser_check_lexeme(p, "|"):
        let pname = parser_advance(p).lexeme
        push(params, Param { name: pname, ty: [], default: None, is_mut: false, span: Span::empty() })
        
        while parser_match_lexeme(p, ","):
            let pname2 = parser_advance(p).lexeme
            push(params, Param { name: pname2, ty: [], default: None, is_mut: false, span: Span::empty() })
    
    let _ = parser_expect(p, "|")
    let body = parse_expr_v2(p)
    
    return Expr::Lambda(params, body)

// =============================================================================
// Statement Parsing
// =============================================================================

fn parse_stmt_v2(p: ParserV2) -> Stmt:
    if !parser_inc_nest(p):
        return Stmt::Expr(Expr::None)
    
    let tok = parser_peek(p)
    let result = Stmt::Expr(Expr::None)
    
    if tok.is_keyword("let"):
        result = parse_let_v2(p)
    else if tok.is_keyword("var"):
        result = parse_var_v2(p)
    else if tok.is_keyword("return"):
        result = parse_return_v2(p)
    else if tok.is_keyword("if"):
        result = parse_if_v2(p)
    else if tok.is_keyword("while"):
        result = parse_while_v2(p)
    else if tok.is_keyword("for"):
        result = parse_for_v2(p)
    else if tok.is_keyword("loop"):
        result = parse_loop_v2(p)
    else if tok.is_keyword("match"):
        result = parse_match_v2(p)
    else if tok.is_keyword("break"):
        let _ = parser_advance(p)
        result = Stmt::Break
    else if tok.is_keyword("continue"):
        let _ = parser_advance(p)
        result = Stmt::Continue
    else if str_eq(tok.lexeme, "pass"):
        let _ = parser_advance(p)
        result = Stmt::Expr(Expr::Ident("pass"))
    else:
        // Expression statement
        let expr = parse_expr_v2(p)
        
        // Check for assignment
        if parser_match_lexeme(p, "="):
            parser_skip_newlines(p)
            let value = parse_expr_v2(p)
            result = Stmt::Assign(expr, value)
        else:
            result = Stmt::Expr(expr)
    
    parser_dec_nest(p)
    return result

fn parse_let_v2(p: ParserV2) -> Stmt:
    let _ = parser_expect_keyword(p, "let")
    let name = parser_advance(p).lexeme
    
    // Optional type annotation
    let ty = None
    if parser_match_lexeme(p, ":"):
        ty = Some(type_expr_to_string(parse_type_expr(p)))
    
    let _ = parser_expect(p, "=")
    parser_skip_newlines(p)
    let value = parse_expr_v2(p)
    return Stmt::Let(name, ty, value)

fn parse_var_v2(p: ParserV2) -> Stmt:
    let _ = parser_expect_keyword(p, "var")
    let name = parser_advance(p).lexeme
    
    let ty = None
    if parser_match_lexeme(p, ":"):
        ty = Some(type_expr_to_string(parse_type_expr(p)))
    
    let _ = parser_expect(p, "=")
    parser_skip_newlines(p)
    let value = parse_expr_v2(p)
    return Stmt::Var(name, ty, value)

fn parse_return_v2(p: ParserV2) -> Stmt:
    let _ = parser_expect_keyword(p, "return")
    
    let tok = parser_peek(p)
    if str_eq(variant_of(tok.type), "Newline") || str_eq(variant_of(tok.type), "Dedent") || str_eq(variant_of(tok.type), "Eof"):
        return Stmt::Return(None)
    
    let expr = parse_expr_v2(p)
    return Stmt::Return(Some(expr))

fn parse_if_v2(p: ParserV2) -> Stmt:
    let _ = parser_expect_keyword(p, "if")
    let cond = parse_expr_v2(p)
    let _ = parser_expect(p, ":")
    parser_skip_newlines(p)
    let then_block = parse_block_v2(p)
    
    parser_skip_newlines(p)
    let else_block = None
    
    if parser_match_keyword(p, "else"):
        if parser_check_lexeme(p, "if"):
            // else if - parse as nested if in else block
            let nested_if = parse_if_v2(p)
            else_block = Some([nested_if])
        else:
            let _ = parser_expect(p, ":")
            parser_skip_newlines(p)
            else_block = Some(parse_block_v2(p))
    
    return Stmt::If(cond, then_block, else_block)

fn parse_while_v2(p: ParserV2) -> Stmt:
    let _ = parser_expect_keyword(p, "while")
    let cond = parse_expr_v2(p)
    let _ = parser_expect(p, ":")
    parser_skip_newlines(p)
    let body = parse_block_v2(p)
    return Stmt::While(cond, body)

fn parse_for_v2(p: ParserV2) -> Stmt:
    let _ = parser_expect_keyword(p, "for")
    let var_name = parser_advance(p).lexeme
    let _ = parser_expect_keyword(p, "in")
    let iter = parse_expr_v2(p)
    let _ = parser_expect(p, ":")
    parser_skip_newlines(p)
    let body = parse_block_v2(p)
    return Stmt::For(var_name, iter, body)

fn parse_loop_v2(p: ParserV2) -> Stmt:
    let _ = parser_expect_keyword(p, "loop")
    let _ = parser_expect(p, ":")
    parser_skip_newlines(p)
    let body = parse_block_v2(p)
    return Stmt::Loop(body)

fn parse_match_v2(p: ParserV2) -> Stmt:
    let _ = parser_expect_keyword(p, "match")
    let scrutinee = parse_expr_v2(p)
    let _ = parser_expect(p, ":")
    parser_skip_newlines(p)
    
    // Expect indent for match arms
    if !parser_match(p, "Indent"):
        parser_error(p, "Expected indented block for match arms")
    
    let arms = []
    
    while !parser_match(p, "Dedent"):
        if parser_is_eof(p):
            parser_error(p, "Unexpected EOF in match expression")
            break
        
        // Skip newlines
        if parser_check(p, "Newline"):
            let _ = parser_advance(p)
            continue
        
        // Parse pattern
        let pattern = parse_pattern_v2(p)
        parser_skip_ws(p, ParseContext::Parens)
        
        // Optional guard
        let guard = None
        if parser_match_keyword(p, "if"):
            guard = Some(parse_expr_v2(p))
            parser_skip_ws(p, ParseContext::Parens)
        
        let _ = parser_expect(p, "=>")
        parser_skip_ws(p, ParseContext::Block)
        
        // Parse body
        let body = []
        if parser_check(p, "Indent"):
            body = parse_block_v2(p)
        else:
            let stmt = parse_stmt_v2(p)
            push(body, stmt)
        
        // Convert PatternV2 to Pattern for now (legacy compatibility)
        let legacy_pattern = pattern_v2_to_legacy(pattern)
        push(arms, MatchArm { pattern: legacy_pattern, guard: guard, body: body, span: Span::empty() })
    
    return Stmt::Match(scrutinee, arms)

// Helper to convert new pattern to legacy pattern
fn pattern_v2_to_legacy(p: PatternV2) -> Pattern:
    match p:
        Wildcard => return Pattern::Wildcard
        Ident(name) => return Pattern::Ident(name)
        Literal(expr) => return Pattern::Literal(expr)
        Variant(enum_name, var_name, bindings) =>
            let legacy_bindings = []
            for b in bindings:
                push(legacy_bindings, pattern_v2_to_legacy(b))
            return Pattern::Variant(enum_name, var_name, legacy_bindings)
        Tuple(patterns) =>
            let legacy_patterns = []
            for pat in patterns:
                push(legacy_patterns, pattern_v2_to_legacy(pat))
            return Pattern::Tuple(legacy_patterns)
        Struct(name, fields) =>
            let legacy_fields = []
            for f in fields:
                let fname = f.name
                let fpat = f.pattern
                let legacy_fpat = pattern_v2_to_legacy(fpat)
                push(legacy_fields, FieldPattern { name: fname, pattern: legacy_fpat, span: Span::empty() })
            return Pattern::Struct(name, legacy_fields)
        Or(patterns) =>
            let legacy_patterns = []
            for pat in patterns:
                push(legacy_patterns, pattern_v2_to_legacy(pat))
            return Pattern::Or(legacy_patterns)
        As(inner, name) =>
            // Legacy doesn't have as pattern
            return Pattern::Ident(name)
        Rest =>
            return Pattern::Wildcard
    return Pattern::Wildcard

// =============================================================================
// Block Parsing
// =============================================================================

fn parse_block_v2(p: ParserV2) -> Array<Stmt>:
    let stmts = []
    let max_stmts = 10000
    
    parser_skip_newlines(p)
    
    let has_indent = parser_match(p, "Indent")
    
    while !parser_is_eof(p) && array_len(stmts) < max_stmts:
        let tok = parser_peek(p)
        
        // End of indented block
        if has_indent && parser_check(p, "Dedent"):
            let _ = parser_advance(p)
            break
        
        // Skip newlines
        if parser_check(p, "Newline"):
            let _ = parser_advance(p)
            continue
        
        // Top-level keywords end non-indented blocks
        if !has_indent:
            if is_sync_point(tok):
                break
        
        let start_pos = p.pos
        let stmt = parse_stmt_v2(p)
        push(stmts, stmt)
        
        // Safety check
        if p.pos == start_pos:
            parser_error(p, "Parser stuck, advancing")
            let _ = parser_advance(p)
            if p.pos == start_pos:
                break
        
        // Non-indented blocks are single statement
        if !has_indent:
            break
    
    return stmts

// =============================================================================
// Top-Level Parsing
// =============================================================================

fn parse_item_v2(p: ParserV2) -> Item:
    let tok = parser_peek(p)
    let lex = tok.lexeme
    
    if str_eq(lex, "fn"):
        let f = parse_fn_def_v2(p, false, false)
        return Item::Function(f)
    else if str_eq(lex, "pub"):
        let _ = parser_advance(p)
        let next = parser_peek(p)
        if str_eq(next.lexeme, "fn"):
            let f = parse_fn_def_v2(p, true, false)
            return Item::Function(f)
        else if str_eq(next.lexeme, "struct"):
            let s = parse_struct_def_v2(p, true)
            return Item::Struct(s)
        else:
            parser_error(p, "Expected 'fn' or 'struct' after 'pub'")
            parser_advance_to_sync(p)
            return Item::Function(FnDef {
                name: "_error",
                generics: [],
                params: [],
                return_type: None,
                body: [],
                is_pub: false,
                is_async: false,
                effects: [],
                span: Span::empty()
            })
    else if str_eq(lex, "async"):
        let _ = parser_advance(p)
        if !parser_match_keyword(p, "fn"):
            parser_error(p, "Expected 'fn' after 'async'")
        let f = parse_fn_def_v2(p, false, true)
        return Item::Function(f)
    else if str_eq(lex, "struct"):
        let s = parse_struct_def_v2(p, false)
        return Item::Struct(s)
    else if str_eq(lex, "enum"):
        let e = parse_enum_def_v2(p)
        return Item::Enum(e)
    else if str_eq(lex, "impl"):
        let i = parse_impl_def_v2(p)
        return Item::Impl(i)
    else if str_eq(lex, "use"):
        let u = parse_use_v2(p)
        return Item::Use(u)
    else if str_eq(lex, "extern"):
        let e = parse_extern_fn_v2(p)
        return Item::ExternFn(e)
    else:
        parser_error(p, "Unexpected token at top level: '" + lex + "'")
        parser_advance_to_sync(p)
        return Item::Use("_error")

/// Parse an extern function declaration: extern fn name(params) -> ReturnType
fn parse_extern_fn_v2(p: ParserV2) -> ExternFnDef:
    // Consume 'extern'
    let _ = parser_advance(p)
    
    // Expect 'fn'
    if !parser_match_keyword(p, "fn"):
        parser_error(p, "Expected 'fn' after 'extern'")
    
    // Get function name
    let name = parser_advance(p).lexeme
    
    // Parse parameters (parse_params_v2 handles the parentheses)
    let params = parse_params_v2(p)
    
    // Parse optional return type
    let return_type = []
    if parser_check_lexeme(p, "->"):
        let _ = parser_advance(p)
        return_type = [type_expr_to_string(parse_type_expr(p))]
    
    return ExternFnDef {
        name: name,
        params: params,
        return_type: return_type,
        span: Span::empty()
    }

fn parse_fn_def_v2(p: ParserV2, is_pub: Bool, is_async: Bool) -> FnDef:
    if parser_check_keyword(p, "fn"):
        let _ = parser_advance(p)
    
    let name = parser_advance(p).lexeme
    
    // Generics
    let generics = []
    if parser_match_lexeme(p, "<"):
        while !parser_check_lexeme(p, ">"):
            push(generics, parser_advance(p).lexeme)
            if parser_check_lexeme(p, ","):
                let _ = parser_advance(p)
        let _ = parser_expect(p, ">")
    
    // Parameters
    let params = parse_params_v2(p)
    
    // Return type - use Array<String> to match AST definition
    let return_type = []
    if parser_match_lexeme(p, "->"):
        return_type = [type_expr_to_string(parse_type_expr(p))]
    
    // Effects
    let effects = []
    if parser_match_keyword(p, "with"):
        push(effects, parser_advance(p).lexeme)
    
    // Body
    let _ = parser_expect(p, ":")
    parser_skip_newlines(p)
    let body = parse_block_v2(p)
    
    return FnDef {
        name: name,
        params: params,
        generics: generics,
        return_type: return_type,
        body: body,
        effects: effects,
        span: Span::empty(),
        is_pub: is_pub,
        is_async: is_async
    }

fn parse_params_v2(p: ParserV2) -> Array: // <Param>
    let None = Option::None
    let _ = parser_expect(p, "(")
    let params = []
    
    parser_skip_ws(p, ParseContext::Parens)
    
    while !parser_check_lexeme(p, ")"):
        // Handle 'self'
        if parser_match_keyword(p, "self"):
            push(params, Param { name: "self", ty: ["Self"], default: None, is_mut: false, span: Span::empty() })
            if parser_check_lexeme(p, ","):
                let _ = parser_advance(p)
            parser_skip_ws(p, ParseContext::Parens)
            continue
        
        let tok = parser_peek(p)
        if !tok.is_ident():
            break
        
        let pname = parser_advance(p).lexeme
        let pty = []
        
        if parser_match_lexeme(p, ":"):
            parser_skip_ws(p, ParseContext::Parens)
            pty = [type_expr_to_string(parse_type_expr(p))]
        
        push(params, Param { name: pname, ty: pty, default: None, is_mut: false, span: Span::empty() })
        
        if parser_check_lexeme(p, ","):
            let _ = parser_advance(p)
        parser_skip_ws(p, ParseContext::Parens)
    
    let _ = parser_expect(p, ")")
    return params

fn parse_struct_def_v2(p: ParserV2, is_pub: Bool) -> StructDef:
    let None = Option::None
    let _ = parser_expect_keyword(p, "struct")
    let name = parser_advance(p).lexeme
    let _ = parser_expect(p, ":")
    parser_skip_newlines(p)
    
    if !parser_match(p, "Indent"):
        parser_error(p, "Expected indented block for struct fields")
    
    let fields = []
    
    while !parser_match(p, "Dedent"):
        if parser_is_eof(p):
            break
        if parser_check(p, "Newline"):
            let _ = parser_advance(p)
            continue
        
        let fname = parser_advance(p).lexeme
        let _ = parser_expect(p, ":")
        let ftype = type_expr_to_string(parse_type_expr(p))
        push(fields, FieldDef { name: fname, ty: ftype, default: None, is_pub: false, span: Span::empty() })
    
    return StructDef {
        name: name,
        generics: [],
        fields: fields,
        is_pub: is_pub,
        span: Span::empty()
    }

fn parse_enum_def_v2(p: ParserV2) -> EnumDef:
    let _ = parser_expect_keyword(p, "enum")
    let name = parser_advance(p).lexeme
    let _ = parser_expect(p, ":")
    parser_skip_newlines(p)
    
    if !parser_match(p, "Indent"):
        parser_error(p, "Expected indented block for enum variants")
    
    let variants = []
    
    while !parser_match(p, "Dedent"):
        if parser_is_eof(p):
            break
        if parser_check(p, "Newline"):
            let _ = parser_advance(p)
            continue
        
        let vname = parser_advance(p).lexeme
        let vfields = []
        
        if parser_match_lexeme(p, "("):
            parser_skip_ws(p, ParseContext::Parens)
            if !parser_check_lexeme(p, ")"):
                push(vfields, type_expr_to_string(parse_type_expr(p)))
                while parser_match_lexeme(p, ","):
                    parser_skip_ws(p, ParseContext::Parens)
                    push(vfields, type_expr_to_string(parse_type_expr(p)))
            let _ = parser_expect(p, ")")
        
        push(variants, VariantDef { name: vname, fields: vfields, span: Span::empty() })
    
    return EnumDef {
        name: name,
        generics: [],
        variants: variants,
        span: Span::empty()
    }

fn parse_impl_def_v2(p: ParserV2) -> ImplDef:
    let _ = parser_expect_keyword(p, "impl")
    let type_name = parser_advance(p).lexeme
    
    // Check for trait impl: impl Trait for Type
    let trait_name = []
    if parser_match_keyword(p, "for"):
        trait_name = [type_name]
        type_name = parser_advance(p).lexeme
    
    let _ = parser_expect(p, ":")
    parser_skip_newlines(p)
    
    if !parser_match(p, "Indent"):
        parser_error(p, "Expected indented block for impl methods")
    
    let methods = []
    
    while !parser_match(p, "Dedent"):
        if parser_is_eof(p):
            break
        if parser_check(p, "Newline"):
            let _ = parser_advance(p)
            continue
        
        let is_pub = parser_match_keyword(p, "pub")
        
        if parser_check_keyword(p, "fn"):
            let method = parse_fn_def_v2(p, is_pub, false)
            push(methods, [method])
        else:
            parser_error(p, "Expected 'fn' in impl block")
            parser_advance_to_sync(p)
    
    return ImplDef {
        target: type_name,
        generics: [],
        trait_name: trait_name,
        methods: methods,
        span: Span::empty()
    }

fn parse_use_v2(p: ParserV2) -> String:
    let _ = parser_expect_keyword(p, "use")
    let path = parser_advance(p).lexeme
    
    // Handle :: path segments (e.g., stdlib::math)
    while parser_check_lexeme(p, "::"):
        let _ = parser_advance(p)  // consume ::
        let segment = parser_advance(p).lexeme
        path = path + "::" + segment
    
    // Check for alias 'as'
    if parser_match_keyword(p, "as"):
        let _ = parser_advance(p)
        // Alias ignored in legacy AST Item::Use(String)
        
    return path

// =============================================================================
// Main Entry Point
// =============================================================================

pub fn parse_program_v2(p: ParserV2) -> Array<Item>:
    // println("DEBUG: parse_program_v2 starting for " + p.file)
    let items = []
    
    parser_skip_newlines(p)
    
    while !parser_is_eof(p):
        // Skip spurious indents at top level
        while parser_check(p, "Indent") || parser_check(p, "Dedent"):
            let _ = parser_advance(p)
            parser_skip_newlines(p)
        
        if parser_is_eof(p):
            break
        
        let start_pos = p.pos
        let item = parse_item_v2(p)
        push(items, item)
        
        // Safety check
        if p.pos == start_pos:
            parser_error(p, "Parser stuck at top level")
            let _ = parser_advance(p)
        
        parser_skip_newlines(p)
    
    // Report errors with file:line:column
    if array_len(p.errors) > 0:
        println("")
        for err in p.errors:
            let loc = err.span.location(p.source)
            // Format: error: message
            //   --> file:line:column
            //    |
            // NN | source line
            //    |    ^^^
            println("\x1b[1;31m" + err.severity + "\x1b[0m: " + err.message)
            println("  \x1b[1;34m-->\x1b[0m " + p.file + ":" + str(loc.line) + ":" + str(loc.column))
            println("   |")
            println(" " + str(loc.line) + " | " + loc.source_line)
            // Caret line
            let padding = repeat_char_local(" ", loc.column - 1 + str_len(str(loc.line)) + 4)
            let carets = "^"
            if loc.length > 1:
                carets = carets + repeat_char_local("~", loc.length - 1)
            println(padding + "\x1b[1;31m" + carets + "\x1b[0m")
            println("")
        println("[PARSER] " + str(array_len(p.errors)) + " error(s) found")
    
    return items

fn repeat_char_local(ch: String, n: Int) -> String:
    let result = ""
    let i = 0
    while i < n:
        result = result + ch
        i = i + 1
    return result

// Helper for keyword checking
fn parser_check_keyword(p: ParserV2, kw: String) -> Bool:
    let tok = parser_peek(p)
    return tok.is_keyword(kw)
